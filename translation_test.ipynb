{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgMO5dnb7KJF"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "dataset = load_dataset('multi_eurlex', language='en',label_level='level_2',trust_remote_code=True)\n",
        "dataset3 = load_dataset('multi_eurlex', language='fr',label_level='level_2',trust_remote_code=True)\n",
        "\n",
        "df=pd.DataFrame(dataset['train'])\n",
        "df3=pd.DataFrame(dataset3['train'])"
      ],
      "metadata": {
        "id": "cdGGa4XID5tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-fr-en\")\n",
        "encoded_inputs=tokenizer.batch_encode_plus(list(df3.text),max_length=512, padding='max_length',truncation=True)\n",
        "encoded_inputs_val=tokenizer.batch_encode_plus(list(df.text),max_length=512, padding='max_length',truncation=True)\n",
        "encoded_inputs[\"labels\"] = encoded_inputs_val[\"input_ids\"]\n",
        "from datasets import Dataset\n",
        "tokenized_dataset=Dataset.from_dict(encoded_inputs)"
      ],
      "metadata": {
        "id": "TuxCbgtSVJL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-en-fr\")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./finetuned_en_fr',\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=3,\n",
        "    save_steps=500,\n",
        "    eval_steps=500,\n",
        "    logging_steps=100,\n",
        "    save_total_limit=2,\n",
        "    report_to=[]\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    eval_dataset=tokenized_dataset,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "model.save_pretrained(\"drive/MyDrive/finetuned-en-fr\")\n",
        "tokenizer.save_pretrained(\"drive/MyDrive/finetuned-en-fr\")\n",
        "\n"
      ],
      "metadata": {
        "id": "cJvcDrytYGHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "translator = pipeline(\"translation\", model=model, tokenizer=tokenizer)\n",
        "translations = translator(list(df2.text), max_length=512, truncation=True)"
      ],
      "metadata": {
        "id": "gO88p2zPYGlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset,random_split\n",
        "\n",
        "# Load the pre-trained EuroVoc classifier\n",
        "model_name = \"FacebookAI/xlm-roberta-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name,num_labels=127)\n",
        "device=torch.device('cuda')\n",
        "model=model.to(device)\n",
        "loss_fn=nn.BCEWithLogitsLoss()\n",
        "model.load_state_dict(torch.load('drive/MyDrive/best_model_nonfrozen.pt'))"
      ],
      "metadata": {
        "id": "kPnqa0FKYZml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "encoded_inputs_val=tokenizer.batch_encode_plus(translations, max_length=512, padding='max_length',truncation=True)\n",
        "labels_val=torch.tensor(df2.drop(columns=['text']).values,dtype=torch.float)\n",
        "\n",
        "full_test_set=TensorDataset(torch.tensor(encoded_inputs_val['input_ids']),torch.tensor(encoded_inputs_val['attention_mask']),labels_val)\n",
        "\n",
        "test_loader=DataLoader(full_test_set,batch_size=8,shuffle=False)"
      ],
      "metadata": {
        "id": "dzytB7yEYKWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_losses=[]\n",
        "val_accs=[]\n",
        "r_scores=[]\n",
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  for step,(input_ids,attention_mask,labe) in enumerate(test_loader):\n",
        "    outputs=model(input_ids=input_ids.to(device),attention_mask=attention_mask.to(device))\n",
        "    loss=loss_fn(outputs.logits,labe.to(device))\n",
        "    val_losses.append(float(loss.cpu()))\n",
        "    targ_labs=(outputs.logits>0).float().cpu()\n",
        "    val_accs.append((targ_labs==labe.cpu()).float().mean())\n",
        "    r_score=r_precision(labe.cpu(),outputs.logits.cpu())\n",
        "    r_scores.append(r_score)\n",
        "\n",
        "vloss=np.array(val_losses).mean()\n",
        "r_score=np.array(r_scores).mean()\n",
        "print(f'Test on french: Val Loss={vloss:0.4f}; Val accuracy={np.array(val_accs).mean():0.4f}; R={r_score:0.4f}')"
      ],
      "metadata": {
        "id": "Oq1DG5rGYOPq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}